# Tarea 1 - Llamadas al sistema e implementaci√≥n de una shell

En esta primera tarea del curso trabajar√°s directamente con un kernel real. El kernel utilizado es una adaptaci√≥n de Unix versi√≥n 6 (1975), llamada xv6, que ha sido portada a la arquitectura x86 para ejecutarse en hardware moderno. El Unix original corr√≠a en un [PDP-11](https://en.wikipedia.org/wiki/PDP-11), y su c√≥digo fuente estaba escrito en C, lo que permiti√≥ su portabilidad a distintas arquitecturas y hoy hace posible que podamos experimentar con √©l en este curso.

El objetivo de la tarea es introducirte en la programaci√≥n a nivel de kernel (kernel hacking) y en la implementaci√≥n de algoritmos de planificaci√≥n de procesos. Para ello, la tarea se divide en dos etapas:

* Parte 1.1 ‚Äì Fecha de entrega 5/9 23:59 - Llamadas al sistema: deber√°s implementar nuevas syscalls en xv6 (`waitx`, `setgroup`, `getgroup`). Esta parte te permitir√° comprender c√≥mo se agregan funcionalidades al sistema operativo, c√≥mo se comunican los programas de usuario con el kernel, y c√≥mo se manejan estructuras internas de procesos.
* Parte 1.2 ‚Äì Fecha de entrega 22/9 23:59 -  Planificador FSS (Fair Share Scheduler): utilizando las llamadas implementadas en la primera parte, modificar√°s el scheduler por defecto de xv6 para implementar un planificador basado en grupos, de manera que los procesos se repartan el tiempo de CPU en proporciones justas seg√∫n su pertenencia a un grupo. Esta parte te permitir√° observar de manera pr√°ctica c√≥mo los algoritmos de planificaci√≥n afectan al comportamiento del sistema.

De esta forma, pasar√°s desde implementar llamadas b√°sicas hasta alterar un componente central del sistema operativo: el scheduler. Esto te dar√° una visi√≥n concreta de c√≥mo las abstracciones que estudias a nivel te√≥rico (llamadas al sistema, procesos, planificaci√≥n) se materializan en c√≥digo real de un kernel.

## √çndice

- [Modalidad de trabajo](#modalidad-de-trabajo)
- [Tarea 1.1: Nuevas llamadas al sistema (50% de la nota final)](#tarea-11-nuevas-llamadas-al-sistema-50-de-la-nota-final)
  - [waitx()](#waitx)
  - [setgroup()](#setgroup)
  - [getgroup()](#getgroup)
  - [Primeros pasos](#primeros-pasos)
  - [Compilaci√≥n, Ejecuci√≥n y Depuraci√≥n](#compilaci√≥n-ejecuci√≥n-y-depuraci√≥n)
  - [Requisitos Espec√≠ficos](#tarea-11-requisitos-espec√≠ficos)
  - [Test Automatizado](#test-automatizado)
  - [Compilaci√≥n en macOS](#instrucciones-espec√≠ficas-para-compilar-en-macos)
- [Declaraci√≥n de uso de LLMs (Parte 1)](#declaraci√≥n-de-uso-de-llms)
- [Tarea 1.2: Implementaci√≥n de Fair Share Scheduling (FSS)](#tarea-12-implementaci√≥n-de-fair-share-scheduling-fss-en-xv6)
  - [Descripci√≥n t√©cnica de FSS](#descripci√≥n-t√©cnica-de-fair-share-scheduling-fss-stride-scheduling)
  - [Desarrollo de la Tarea](#desarrollo-de-la-tarea-50-de-la-nota)
  - [Casos de prueba](#casos-de-prueba-35-de-la-nota)
  - [Informe de Segunda Parte](#informe-de-segunda-parte-15-de-la-nota)
- [Declaraci√≥n de uso de LLMs (Parte 2)](#declaraci√≥n-de-uso-de-llms-1)

## Modalidad de trabajo

Esta tarea deber√° ser resuelta en parejas. La totalidad del trabajo debe realizarse en el repositorio clonado despu√©s de aceptar la invitaci√≥n en GitHub classroom. Para la entrega, se considerar√° la √∫ltima revisi√≥n en el repositorio anterior a la fecha y hora de entrega. Para las partes 1 y 2 de la tarea las fechas de entrega son las siguientes:

* Primera parte (1.1, 50% de la nota): 5 de septiembre, 23:59 hrs.
* Segunda parte (1.2, 50% de la nota): 22 de septiembre, 23:59 hrs.

# Tarea 1.1: Nuevas Llamadas al Sistema para Implementar FSS

En esta primera parte deber√°s agregar tres nuevas llamadas al sistema al kernel de xv6.  
El objetivo es familiarizarse con la implementaci√≥n de *syscalls* y preparar las herramientas necesarias para la segunda parte de la tarea.

## `waitx()`

La llamada `waitx()` es una extensi√≥n de la llamada est√°ndar `wait()`.  
Adem√°s de esperar a que un proceso hijo termine, devuelve informaci√≥n sobre el tiempo de CPU y el tiempo de espera que acumul√≥ dicho hijo durante su ejecuci√≥n.

**Firma de la llamada:**

```c
int waitx(int *wtime, int *rtime);
```

* `wtime`: tiempo total que el proceso hijo pas√≥ en estado de espera (runnable pero no ejecut√°ndose).
* `rtime`: tiempo total que el proceso hijo pas√≥ en ejecuci√≥n en la CPU.
* Valor de retorno: el PID del hijo terminado (igual que `wait()`), o `-1` en caso de error o si no hay hijos.

## `setgroup()`

La llamada `setgroup()` asigna un proceso a un grupo de planificaci√≥n.
Esto permitir√° que, en la segunda parte de la tarea, el planificador _Fair Share Scheduler_(FSS) reparta la CPU entre grupos en lugar de hacerlo entre procesos individuales.

Firma de la llamada:

```c
int setgroup(int pid, int gid);
```

* `pid`: identificador del proceso cuyo grupo ser√° modificado.
* `gid`: identificador del grupo al cual se desea asignar el proceso.
* Valor de retorno: 0 si la operaci√≥n fue exitosa, o `-1` en caso de error (por ejemplo, si el proceso con pid no existe).

## `getgroup()`

La llamada `getgroup()` permite consultar a qu√© grupo de planificaci√≥n pertenece un proceso.

Firma de la llamada:

```c
int getgroup(int pid);
```

* `pid`: identificador del proceso.
* Valor de retorno: el `gid` del proceso en caso de √©xito, o `-1` en caso de error (por ejemplo, si el proceso con `pid` no existe).

## Primeros pasos

Puedes revisar un [playlist de YouTube](https://youtube.com/playlist?list=PL3yryPU8iwGO2IsoEa_F8_zIytuHIHV37) con tres v√≠deos que explican todo lo necesario para comenzar tu *kernel hacking* despu√©s de clonar el repositorio con el c√≥digo base de la tarea.  

El √∫ltimo v√≠deo, sobre planificaci√≥n de procesos y sincronizaci√≥n, tambi√©n es √∫til que lo veas, incluso si a√∫n no hemos abordado completamente la materia en clases.

Una manera de comenzar a hackear un c√≥digo base relativamente grande como el de xv6 es buscar partes similares a lo que necesitas hacer, y luego **copiar y modificar** esas partes.  

Por ejemplo:  

- Puedes estudiar la implementaci√≥n de una syscall simple como `getpid()`, para ver la estructura completa de c√≥mo se define, se conecta en la tabla de llamadas y se implementa en el kernel.  
- En el caso de `waitx()`, resulta √∫til revisar el c√≥digo de `wait()`, ya que `waitx()` es esencialmente una versi√≥n extendida que, adem√°s de esperar a que un hijo termine, reporta tiempos de CPU (*rtime*) y de espera (*wtime*).

La mayor parte del esfuerzo se concentrar√° en **comprender el c√≥digo existente** y realizar las modificaciones necesarias. La cantidad de c√≥digo nuevo a escribir es relativamente peque√±a.

Finalmente, recuerda que puedes usar el debugger **gdb** para trazar la ejecuci√≥n del kernel.  

- Compila y ejecuta xv6 en modo depuraci√≥n con:  

```bash
make qemu-gdb
```

Luego, en otra terminal, ejecuta:

```bash
gdb kernel
```

Esto abrir√° gdb en modo remoto, conectado a xv6, y te permitir√° inspeccionar paso a paso c√≥mo funciona tu c√≥digo dentro del kernel.

Dentro del kernel no se puede usar `printf()` como en programas de usuario, pero se dispone de funciones equivalentes. La m√°s usada es `cprintf()`, que permite imprimir mensajes en la consola para depuraci√≥n, con un formato similar a `printf()`. En cambio, la funci√≥n `panic()` se utiliza cuando ocurre un error cr√≠tico del cual el kernel no puede recuperarse: imprime un mensaje, muestra informaci√≥n de depuraci√≥n y detiene la ejecuci√≥n del sistema. Ambas funciones son herramientas fundamentales para comprender qu√© ocurre dentro del kernel durante el desarrollo de la tarea.

## Compilaci√≥n, Ejecuci√≥n y Depuraci√≥n

Primero debemos estar seguros de que el set de herramientas de compilaci√≥n necesario est√° instalado y operativo en nuestro ambiente de desarrollo. Para compilar xv6 y los programas de usuario, es necesario contar con un compilador GCC que genere binarios ejecutables para arquitectura Intel i386 de 32 bits, y en formato Executable and Linkable Format (ELF). Este formato es el nativo utilizado por Linux, entonces, si compilas en Linux (o Windows con WSL) normalmente no necesitar√°s instalar nada aparte.  

**Instrucciones espec√≠ficas para compilar en Linux**

Para compilar en Linux, aseg√∫rate de contar con GCC operativo. Respecto al c√≥digo de xv6, aseg√∫rate de que las l√≠neas 37 y 38 del `Makefile` en el directorio ra√≠z de este repositorio est√©n comentadas, y la l√≠nea 40 est√© descomentada y se vea as√≠:

```Makefile
TOOLPREFIX = 
```

En Linux se usa el GCC nativo instalado y por ello se deja el prefijo de herramientas GCC en blanco.

## Tarea 1.1: Requisitos Espec√≠ficos

### 1) `struct proc` (archivo: `kernel/proc.h`) (.5 punto)
Debes **extender** la estructura del proceso con contadores de tiempo y un identificador de grupo:

- `int rtime;` ‚Äî tiempo total en **RUNNING** (ticks de CPU).
- `int wtime;` ‚Äî tiempo total en **RUNNABLE** (ticks esperando CPU).
- `int stime;` ‚Äî (opcional) tiempo total en **SLEEPING** (√∫til para depurar).
- `int gid;` ‚Äî identificador de **grupo** de planificaci√≥n.

Los primeros tres campos ser√°n le√≠dos/escritos por `waitx`. El campo `gid` es requerido por las otras dos _system calls_ que debes implementar.

Para facilitar la contabilidad del tiempo, el kernel de xv6 ya se encuentra parcialmente modificado para realizar contabilidad de ticks (un tick ocurre cada 10 ms aproximadamente; esto se define en `kernel/lapic.c`) de los procesos. La contabilidad de ticks es implementada en la funci√≥n `tick_accounting` en `kernel/proc.c`. Esta funci√≥n itera por toda la tabla de procesos, y debe incrementar (i.e., sumar 1) a los campos `rtime`, `wtime` y `stime` del PCB de cada proceso - dependiendo de cu√°l sea su estado (`RUNNING`, `RUNNABLE` y `SLEEPING`). **Estas operaciones de incremento est√°n pendientes; t√∫ debes implementarlas una vez que definas los campos `rtime`, `wtime` y `stime` en `struct proc`.**

El manejador de traps en `kernel/trap.c` (ver caso `T_IRQ0 + IRQ_TIMER` en funci√≥n `trap`) llama a la funci√≥n `tick_accounting` cada vez que hay una interrupci√≥n de timer.

### 2) Inicializaci√≥n y herencia de campos (archivo: `kernel/proc.c`) (1.0 punto)
Aseg√∫rate de **inicializar** y **mantener** coherentes los campos nuevos:

- En `allocproc()`:
  - inicializa `p->rtime = p->wtime = p->stime = 0;`
  - inicializa `p->gid = 0;` (grupo por defecto)
- En `fork()`:
  - hereda `np->gid = curproc->gid;`
  - opcionalmente vuelve a poner a cero los contadores del **hijo** (`np->rtime = np->wtime = np->stime = 0;`), seg√∫n el dise√±o que uses para medir desde el *fork*.

Nota SMP: estos campos se actualizan de forma segura bajo `ptable.lock` (en `tick_accounting` provisto).

### 3) `waitx`: datos expuestos al espacio de usuario (2.0 puntos)
`waitx` retorna el **PID** del hijo terminado y escribe en los punteros de usuario `wtime`/`rtime` los totales del hijo:

- En `kernel/proc.c`:
  - Implementa `int waitx(int *wtime, int *rtime)` an√°logo a `wait()`, copiando `p->wtime` y `p->rtime` **antes** de liberar el `struct proc` del hijo.
- En `kernel/sysproc.c`:
  - Wrapper `int sys_waitx(void)` que obtiene dos punteros con `argptr()` y llama a `waitx(...)`.

**Enlaces de syscall** (ver punto 5): agrega n√∫mero, tabla y prototipo.

### 4) `setgroup` / `getgroup`: acceso a `gid` de un proceso (1.0 punto)
Necesitas una operaci√≥n de kernel para **asignar** y otra para **consultar** el grupo:

- En `kernel/proc.c`:
  - `int setgroup_k(int pid, int gid)` ‚Äî busca el proceso por `pid` bajo `ptable.lock` y setea `p->gid = gid`. Retorna `0`/`-1`.
  - `int getgroup_k(int pid)` ‚Äî retorna el `gid` del proceso (o `-1` si no existe).

- En `kernel/sysproc.c`:
  - `int sys_setgroup(void)` ‚Äî obtiene `pid` y `gid` con `argint()` y llama a `setgroup_k(...)`.
  - `int sys_getgroup(void)` ‚Äî obtiene `pid` con `argint()` y llama a `getgroup_k(...)`.

Pol√≠tica de permisos m√≠nima: puedes permitir solo `pid == getpid()` para `setgroup`, o permitir al padre cambiar el grupo de sus hijos. Define y documenta tu elecci√≥n.

### 5) Cableado de *syscalls* (archivos varios) (1.0 punto)
Para que el espacio de usuario invoque las nuevas llamadas:

- `kernel/syscall.h`: define `SYS_waitx`, `SYS_setgroup`, `SYS_getgroup` con n√∫meros **no utilizados**.
- `kernel/syscall.c`: 
  - declara `extern int sys_waitx(void);`, `extern int sys_setgroup(void);`, `extern int sys_getgroup(void);`
  - agrega las entradas en la tabla `syscalls[]` en los √≠ndices `SYS_*` respectivos.
- `user/user.h`: prototipos de usuario:
```c
int waitx(int *wtime, int *rtime);
int setgroup(int pid, int gid);
int getgroup(int pid);
```

En `kernel/usys.S`, tienes que agregar:

```c
SYSCALL(waitx)
SYSCALL(setgroup)
SYSCALL(getgroup)
```

### 6) Locks y Consistencia (.5 punto)

* Toda lectura/modificaci√≥n de `struct proc` en estas rutinas debe realizarse bajo `ptable.lock` (como ya hace `wait()`).
* `tick_accounting` (provisto) tambi√©n usa ptable.lock. Evita hacerla dentro de otras regiones cr√≠ticas ajenas (por ejemplo, no dentro de `tickslock`).

## Test Automatizado

Contamos con un test automatizado en espacio de usuario para la parte 1. El programa con la funcionalidad de test se llama `p1_syscalls_test` y puede ser invocado desde la shell de xv6:

```sh
$./p1_syscalls_test
```

**La compilaci√≥n de `p1_syscalls_test` la tienes que activar descomentando la l√≠nea correspondiente en el `Makefile` (l√≠nea 190 aprox)**:

```Makefile
#	$U/_p1_syscalls_test\
```

El programa crea hijos en distintos grupos, cada hijo se auto-asigna su `gid` con `setgroup`(`getpid()`, `gid`), le avisa al padre su `pid` y `gid` por pipe, hace algo de trabajo (CPU o I/O), y termina.

El padre usa `waitx(&w, &r)` para recoger tiempos y muestra una tabla `pid` / `gid` / `rtime` / `wtime`. Adem√°s, valida que setgroup haya surtido efecto.

Ejemplos:

```sh
$ p1_syscalls_test
pid	gid	rtime	wtime
16	1	3	0
17	2	3	3

$ p1_syscalls_test 2 2
pid	gid	rtime	wtime
5	1	2	0
6	1	3	2
7	2	2	5
8	2	3	7
# 2 hijos en gid=1 (CPU), 2 hijos en gid=2 (CPU)

$ p1_syscalls_test 2 2 mixed
pid	gid	rtime	wtime
10	1	3	0
11	1	3	3
12	2	0	126
13	2	0	126
# 2 hijos en gid=1 (CPU), 2 hijos en gid=2 con carga de "I/O"
```

Qu√© comprueba:

* `setgroup(getpid(), gid)` funciona (el hijo lo aplica sobre s√≠ mismo).
* `getgroup(pid)` devuelve el `gid` esperado (si se consulta antes de que el hijo termine).
* `waitx(&w,&r)` devuelve PID y llena `wtime`/`rtime` con valores coherentes (>0 para `rtime` y/o `wtime`, seg√∫n la carga).

Nota: `getgroup(pid)` despu√©s de `waitx` probablemente devuelve `-1` porque el hijo ya fue liberado; por eso el programa usa un _pipe_ (canal de comunicaci√≥n inter-procesos) para conocer `gid` de cada `pid` antes de recolectarlos.

**Instrucciones espec√≠ficas para compilar en macOS**

Si usas un Mac, con procesador Intel o ARM, tendr√°s que instalar una versi√≥n de GCC que genere binarios Intel de 32 bits en formato ELF.

Si usas Mac, debes tener homebrew instalado. Luego, instalas GCC para i686-elf, con el siguiente comando:

```sh
brew install i686-elf-gcc
```

Luego, debes ir al `Makefile` en la ra√≠z de este repositorio y descomentar la l√≠nea 37, que dice:

```Makefile
TOOLPREFIX = i686-elf-
```

Esto activar√° la variable `TOOLPREFIX` con el prefijo `i686-elf` para gcc y binutils, programas que se requieren para compilar correctamente xv6. Si no usas Mac, aseg√∫rate de que dicha l√≠nea est√° comentada. 

**Compilar e iniciar xv6**

Para compilar e iniciar xv6, en el directorio en donde se encuentra el c√≥digo de la tarea, se debe ejecutar el siguiente comando:

```sh 
prompt> make qemu-nox 
```

Para cerrar qemu, se debe presionar la combinaci√≥n de teclas `Ctrl-a-x`.

Si se desea depurar el kernel con gdb, se debe compilar y ejecutar con 

```sh 
prompt> make qemu-nox-gdb
```

En un terminal paralelo, en el directorio del c√≥digo base de la tarea se debe ejecutar gdb:

```sh
prompt> gdb kernel
```

Algunas operaciones comunes con gdb son las siguientes:

* `c` para continuar la depuraci√≥n. **Siempre se debe ingresar este comando cuando se inicia gdb**
* `b archivo:linea` para fijar un _breakpoint_ en cierto `archivo` y `linea` del mismo.
* `backtrace` (o `bt`) para mostrar un resumen de c√≥mo ha sido la ejecuci√≥n hasta el momento.
* `info registers` muestra el estado de registros de la CPU.
* `print`, `p` o `inspect` son √∫tiles para evaluar una expresi√≥n.
*  M√°s informaci√≥n aqu√≠: http://web.mit.edu/gnu/doc/html/gdb_10.html

En el kernel, puedes imprimir mensajes de depuraci√≥n utilizando la funci√≥n `cprintf`, la cual admite strings de formato similares a `printf` de la biblioteca est√°ndar. Puedes ver los detalles de implementaci√≥n en `kernel/console.c`.

Adem√°s, existe la funci√≥n `panic` que permite detener la ejecuci√≥n del kernel cuando ocurre una situaci√≥n de error. Esta funci√≥n muestra una traza de la ejecuci√≥n hasta el momento en que es ejecutada. Los valores que muestra pueden ser buscados en `kernel/kernel.asm` para comprender c√≥mo pudo haberse ejecutado la funci√≥n.

## Declaraci√≥n de uso de LLMs

En esta parte de la tarea est√° permitido el uso de LLMs, pero se debe declarar su uso. Para detalles sobre forma y usos permitidos de LLMs, revisar la √∫ltima secci√≥n de este documento. Si no se entrega un informe apropiado al respecto, el grupo perder√° el derecho a que su trabajo sea evaluado.

# Tarea 1.2: Implementaci√≥n de Fair Share Scheduling (FSS) en xv6

En esta segunda parte de la tarea, el foco estar√° en la planificaci√≥n de procesos. Los sistemas operativos modernos cuentan con planificadores sofisticados, que buscan repartir la CPU de manera eficiente y justa entre los distintos procesos y usuarios. Uno de estos algoritmos es **Fair Share Scheduling (FSS)**, cuyo objetivo es que el tiempo de CPU se distribuya de manera proporcional entre *grupos de procesos* en lugar de hacerlo entre procesos individuales.

Para implementar FSS en xv6, utilizar√°s las llamadas al sistema desarrolladas en la primera parte de la tarea (`waitx`, `setgroup`, `getgroup`). Estas syscalls te permitir√°n:

* Medir el uso real de CPU de cada proceso y grupo.
* Asignar procesos a distintos grupos de planificaci√≥n.
* Consultar a qu√© grupo pertenece cada proceso.

El planificador FSS en xv6 debe garantizar que la CPU se reparta equitativamente seg√∫n los grupos, de modo que si existen dos grupos con distinta cantidad de procesos, ambos reciban una fracci√≥n del procesador de acuerdo a su participaci√≥n relativa, independientemente del n√∫mero de procesos que contengan.

Los objetivos espec√≠ficos de esta segunda parte son:

* Comprender c√≥mo se implementa un algoritmo de planificaci√≥n en el kernel.  
* Utilizar estructuras de datos y syscalls para administrar procesos en grupos de planificaci√≥n.  
* Implementar una variante del algoritmo de planificaci√≥n _Fair Share Scheduling_ (FSS).  
* Evaluar emp√≠ricamente tu implementaci√≥n utilizando programas de prueba dise√±ados para medir la equidad en el reparto de CPU.  

## Descripci√≥n t√©cnica de Fair Share Scheduling (FSS): Stride Scheduling

Una forma pr√°ctica de implementar FSS es mediante el algoritmo de **stride scheduling**, que se basa en los siguientes conceptos:

- **Stride**: cada grupo recibe un valor de stride, calculado como `L / share`, donde `L` es una constante grande (por ejemplo, 10,000) y `share` representa la participaci√≥n del grupo (en nuestro caso, todos los grupos tienen igual participaci√≥n inicial, por lo que `share = 1`).
- **Pass**: cada grupo mantiene un contador llamado *pass value*, que representa el "cr√©dito acumulado" de CPU que ha recibido.  
- **Selecci√≥n**: en cada decisi√≥n de planificaci√≥n, se selecciona el grupo con el menor valor de *pass*. Luego, ese grupo ejecuta uno de sus procesos y su *pass* se incrementa en su `stride`.

De esta forma, los grupos se alternan en funci√≥n de sus *pass values*, logrando un reparto proporcional y estable en el tiempo.

### Procesos dentro de un grupo

Una vez que el planificador selecciona un grupo para ejecutar, debe elegirse un proceso dentro de dicho grupo. Para simplificar, puedes utilizar un esquema **round-robin** (FIFO) entre los procesos del grupo.

### Estructuras requeridas

Para implementar FSS necesitar√°s:

- Mantener informaci√≥n de cada proceso sobre a qu√© grupo pertenece (ya implementado en la primera parte con `setgroup`/`getgroup`).
- Mantener una estructura global que registre, para cada grupo:
  - `gid` (identificador del grupo).
  - `stride` (incremento de *pass* cada vez que le corresponde CPU).
  - `pass` (valor acumulado que define el orden en que ser√° planificado).

### Objetivo del algoritmo

El resultado esperado es que, al ejecutar programas de prueba que consumen intensivamente CPU, el tiempo total de CPU usado por los procesos de cada grupo sea consistente con el reparto **justo** definido por FSS. Por ejemplo, si existen dos grupos, deber√≠an repartirse la CPU aproximadamente en 50% y 50%, independientemente del n√∫mero de procesos en cada uno.

## Desarrollo de la Tarea (50% de la nota)

En esta parte implementar√°s **Fair Share Scheduling** modificando principalmente el **planificador** de xv6. A continuaci√≥n se indican los **puntos del kernel** que debes revisar/tocar y el **flujo m√≠nimo** para que tu FSS funcione.

### 1) D√≥nde trabajar

- **`kernel/proc.c`**
  - `scheduler()` ‚Üê **aqu√≠ va el n√∫cleo de FSS** (selecci√≥n por grupo).
  - (Opcional) Helpers: `fss_pick_group()`, `fss_pick_proc_in_group()`, etc.
  - `fork()` / `allocproc()` ‚Üê aseguran herencia/valor por defecto de `gid`.
- **`kernel/proc.h`**
  - `struct proc` ya tiene `gid` (Parte 1) y contadores (`rtime`, `wtime`, ‚Ä¶).
  - Define una **estructura por grupo** (p. ej. `struct group`) y una peque√±a tabla global.
- **`kernel/defs.h`**
  - Prototipos de tus helpers FSS (si no los defines `static`).

### 2) Estructuras m√≠nimas

Define una tabla de grupos simple:

```c
// proc.h
#define NGROUPS 16
#define FSS_BIG 100000

struct group {
  int  gid;        // identificador de grupo
  int  active;     // 1 si el slot est√° en uso
  uint pass;       // valor de ‚Äúcr√©dito‚Äù acumulado
  uint stride;     // FSS_BIG / share (usa share=1 en esta tarea)
  int  rr_cursor;  // √≠ndice para round-robin dentro del grupo
};

extern struct group gtable[NGROUPS];
```

Inicializa al boot (p. ej. en `pinit()`):

* Marca todos inactivos.
* Asegura `gid=0` activo (los procesos nacen en 0 si no cambias nada).
* `stride = FSS_BIG` (shares iguales).

### 3) Integraci√≥n con setgroup / creaci√≥n de procesos

- En `allocproc()` y **despu√©s** de asignar `p->gid`, llama a un helper tipo `fss_group_ensure(p->gid)` que:  
- Busca el grupo en `gtable` y lo marca activo si no existe.  
- En `fork()`, **hereda** `np->gid = currproc->gid` y vuelve a asegurar el grupo.  
- En `userinit()` (primer proceso):  
```c
p->gid = 0;
fss_group_ensure(0);
```

antes de marcarlo `RUNNABLE`.

Con esto te evitas estados donde hay procesos con `gid` v√°lido pero sin grupo ‚Äúactivo‚Äù en la tabla.

### 4) L√≥gica del scheduler() (n√∫cleo de FSS)

Con `ptable.lock` tomado:

1. Elegir grupo con menor pass que tenga al menos un proceso en estado `RUNNABLE`.
2. Elegir proceso dentro del grupo (round-robin sobre `ptable.proc[]` filtrando por `gid` y `state==RUNNABLE`).
3. Marcar `p->state = RUNNING`, hacer `swtch` (despachar proceso escogido).
4. Al volver del `swtch`, incrementar `pass` del grupo:
 * Versi√≥n simple y suficiente):
 ```c
 g->pass += g->stride;
 ```
5. Soltar `ptable.lock` y continuar el bucle.

Para robustez del algoritmo:

* Si no hay grupo elegible, `release(&ptable.lock); continue;` (no imprimas en loop).
* Si un grupo fue elegido pero ning√∫n `RUNNABLE` se encuentra (carrera), suelta el lock y contin√∫a.

### 5) Concurrencia y locks (Ejecuci√≥n con Multiprocesador; SMP)

* Mant√©n ptable.lock durante:
  * Selecci√≥n de grupo, selecci√≥n de proceso y cambio de state a `RUNNING`.
* Es normal que con **CPUS>1** dos CPUs elijan el mismo grupo si hay varios `RUNNABLE` en √©l; el algoritmo se **auto-corrige** porque ese grupo acumula pass m√°s r√°pido.

### 6) Pol√≠tica de shares (simplificada)

En esta tarea usa shares iguales para todos los grupos:
 * `stride = FSS_BIG / 1`.

### 7) Funciones pre-implementadas

En `proc.h/.c` se incluyen algunas funciones de apoyo para la implementaci√≥n del scheduler **Fair Share Scheduling (FSS)**.  
Algunas est√°n completas y otras se entregan como *stubs* (esqueleto con comentarios), para que ustedes las implementen.  

Estas funciones sirven para manejar la tabla de grupos (`gtable`) y los procesos asociados a cada grupo, de modo que el scheduler pueda decidir qu√© grupo y qu√© proceso ejecutar.

#### `static void fss_init_groups(void)`  
**Estado:** completa  

Inicializa la tabla de grupos (`gtable`).  
Deja todos los grupos como inactivos (`active = 0`) y asegura que el sistema parte sin grupos registrados.  
Se llama al inicio del kernel.

#### `static struct group* fss_group_lookup(int gid)`  
**Estado:** completa  

Busca en la tabla de grupos (`gtable`) un grupo activo cuyo identificador (`gid`) coincida con el argumento.  
- Si lo encuentra, retorna un puntero a ese grupo.  
- Si no lo encuentra, retorna `0`.  

Es √∫til cuando se necesita consultar si un grupo ya est√° registrado en el sistema.

#### `static struct group* fss_group_ensure(int gid)`  
**Estado:** *stub*  

Garantiza que exista un grupo con el `gid` dado.  
- Si ya existe, lo retorna directamente.  
- Si no existe, busca un slot libre en la `gtable`, inicializa un nuevo grupo (activo, con `pass = 0`, `stride = FSS_BIG` y `rr_cursor = 0`) y lo retorna.  
- Si no hay espacio en la `gtable`, retorna `0` (caso muy poco com√∫n en xv6).  

üëâ Esta funci√≥n es la forma est√°ndar de asegurarse de que un `gid` tenga un grupo v√°lido en memoria.

#### `static int fss_group_has_runnable(struct group *g)`  
**Estado:** *stub*  

Verifica si un grupo tiene **al menos un proceso en estado RUNNABLE**.  
- Recorre la tabla de procesos (`ptable.proc`) y busca procesos cuyo `gid` coincida con el del grupo y est√©n en estado `RUNNABLE`.  
- Retorna `1` si encuentra alguno, o `0` si no hay procesos listos para correr en ese grupo.  

Esta funci√≥n permite saber si un grupo puede ser considerado por el scheduler.

#### `static struct group* fss_pick_group(void)`  
**Estado:** *stub*  

Selecciona el **grupo candidato a ejecutar** seg√∫n FSS.  
- Recorre todos los grupos activos en la `gtable`.  
- Descarta los grupos sin procesos RUNNABLE.  
- Elige el grupo con el **menor valor de `pass`** (el que ha consumido menos CPU en t√©rminos relativos).  
- Si no hay grupos v√°lidos, retorna `0`.  

Es la funci√≥n que decide **qu√© grupo tiene el turno de CPU**.

#### `static struct proc* fss_pick_proc_in_group(struct group *g)`  
**Estado:** *stub*  

Selecciona un proceso dentro de un grupo dado, usando **round-robin**:  
- Comienza desde la posici√≥n `rr_cursor` del grupo.  
- Busca un proceso `RUNNABLE` en `ptable.proc` con el mismo `gid`.  
- Si encuentra uno, lo retorna y actualiza `rr_cursor` para la pr√≥xima vez.  
- Si no encuentra en la primera pasada, envuelve y busca desde el inicio hasta `rr_cursor`.  
- Si no hay ninguno, retorna `0`.  

Permite repartir la CPU de manera justa **entre los procesos de un mismo grupo**.

### Resumen del rol de estas funciones

- **Inicializaci√≥n y lookup:** `fss_init_groups`, `fss_group_lookup`, `fss_group_ensure`  
- **Chequeo de procesos disponibles:** `fss_group_has_runnable`  
- **Selecci√≥n de grupo y proceso:** `fss_pick_group`, `fss_pick_proc_in_group`

En conjunto, estas funciones permiten que el scheduler FSS:
1. Mantenga los grupos organizados.  
2. Elija el grupo menos favorecido en CPU (`pass` m√°s bajo).  
3. Dentro de ese grupo, elija un proceso en orden circular (round-robin).  

## Casos de prueba (35% de la nota)

Para evaluar la correcta implementaci√≥n del planificador **Fair Share Scheduler (FSS)**, se entrega una herramienta de pruebas llamada **fss_bench** junto con un script de automatizaci√≥n **grade.sh**.  

### Herramienta fss_bench

`fss_bench` es un programa de usuario que genera una carga controlada de procesos, asign√°ndolos a distintos grupos de planificaci√≥n y ejecutando patrones de trabajo (CPU-bound o con pausas `sleep`). Al finalizar, el programa imprime para cada proceso:

- `pid`: identificador del proceso.
- `gid`: identificador del grupo al que pertenece.
- `rtime`: tiempo total en CPU (ticks).
- `wtime`: tiempo total esperando (ticks).

Adem√°s, reporta el total de tiempo de CPU usado por cada grupo y el reparto porcentual observado.

**La compilaci√≥n de `fss_bench` la tienes que activar descomentando la l√≠nea correspondiente en el Makefile (l√≠nea 190 aprox):**

```Makefile
#	$U/_fss_bench\
```

### Script grade.sh

El script `grade.sh` debe invocarse en el sistema operativo host (no en qemu):

```sh
./grade.sh
```

Este script automatiza la ejecuci√≥n de `fss_bench` bajo distintos escenarios de prueba, compara los resultados con lo esperado y reporta si se cumple la pol√≠tica de reparto justo de CPU.  
En esta tarea se consideran √∫nicamente **dos casos de prueba**:  

#### Caso C1: CPU-bound (1 vs 3 procesos)

- Configuraci√≥n: un grupo A con 1 proceso intensivo en CPU, y un grupo B con 3 procesos tambi√©n intensivos en CPU.  
- Objetivo: el FSS debe repartir el tiempo de CPU entre grupos de forma justa (‚âà50% para A y ‚âà50% para B), independientemente del n√∫mero de procesos en cada grupo.  
- Tolerancia: se acepta un rango de ¬±10% en el reparto observado.  

#### Caso C2: Carga mixta (2 vs 2 procesos)

- Configuraci√≥n: un grupo A con 2 procesos CPU-bound, y un grupo B con 2 procesos que combinan CPU y llamadas a `sleep`.  
- Objetivo: aun cuando los procesos de B hagan pausas, el planificador debe garantizar que, en promedio, el grupo B reciba aproximadamente el mismo porcentaje de CPU que el grupo A (‚âà50% / 50%).  
- Tolerancia: nuevamente se acepta un rango de ¬±10%.  

### Interpretaci√≥n de resultados

El script imprimir√° los resultados de cada caso. Un ejemplo t√≠pico de salida es:

```sh
pid gid rtime wtime
4 1 399 401
5 2 170 667
6 2 154 723
7 2 156 723

GROUP A (gid=1) CPU total rtime: 399
GROUP B (gid=2) CPU total rtime: 480
CPU share A/B: 45% / 55% (tolerance_share=10%)
```

Si la implementaci√≥n cumple con los objetivos de FSS, el script marcar√° el caso como aprobado.  

## Informe de Segunda Parte (15% de la nota)

La segunda parte de la tarea requiere un informe, con el siguiente formato:

* Archivo **INFORME.md** en el directorio ra√≠z del c√≥digo fuente de xv6.
* Al inicio del archivo deben aparecer los nombres completos de los integrantes del grupo.
* El informe debe contener las siguientes secciones, cada una explicando c√≥mo se implement√≥ la funcionalidad respectiva.  
* En cada secci√≥n se deben incluir referencias al c√≥digo fuente modificado, indicando n√∫meros de l√≠nea relevantes.  
* Se recomienda utilizar el [formato markdown de GitHub](https://guides.github.com/features/mastering-markdown/) para mostrar ejemplos de c√≥digo y fragmentos.

### Secciones requeridas

1. **Cambios en estructuras de datos**  
   Explicar qu√© campos se agregaron en las estructuras principales (por ejemplo `struct proc` y `struct gtable`).  
   Indicar c√≥mo se inicializan esos campos y en qu√© partes del kernel.  

2. **Integraci√≥n con syscalls `setgroup` y `getgroup`**  
   Describir c√≥mo se utilizan estas llamadas en la asignaci√≥n de grupos.  
   Explicar c√≥mo se asegura la creaci√≥n de grupos en `allocproc`, `fork` y `userinit`.  

3. **Modificaciones en `scheduler()`**  
   Explicar c√≥mo se cambi√≥ la l√≥gica de selecci√≥n de procesos para implementar FSS.  
   Indicar c√≥mo se elige el grupo, c√≥mo se mantiene la variable `pass`, y c√≥mo se realiza la selecci√≥n de procesos dentro de un grupo.  

4. **Manejo de concurrencia y locks**  
   Describir qu√© decisiones se tomaron respecto a `ptable.lock` y c√≥mo se asegura consistencia entre CPUs.  

5. **Pruebas realizadas**  
   Explicar c√≥mo se usaron los programas de prueba (`p1_syscalls_test`, `fss_bench`, `grade.sh`) para validar la implementaci√≥n.  
   Mostrar ejemplos de ejecuciones que demuestren que el reparto de CPU cumple con lo esperado.  

---

El informe no debe ser extenso; basta con **unas pocas p√°ginas** que expliquen las ideas principales y dejen constancia de que el grupo entendi√≥ c√≥mo y por qu√© funciona su implementaci√≥n.

## Declaraci√≥n de uso de LLMs

En esta tarea se permite el uso de modelos de lenguaje (LLMs), como ChatGPT, GitHub Copilot, Claude, Gemini, entre otros.  
El uso de estas herramientas debe ser **declarado expl√≠citamente** en el archivo `INFORME.md`, en una secci√≥n llamada **Uso de LLMs**.

En dicha secci√≥n, el grupo debe indicar:

* **Herramienta utilizada**: nombre y versi√≥n aproximada (ejemplo: *ChatGPT GPT-4, GitHub Copilot*).  
* **Prop√≥sito del uso**: breve descripci√≥n de para qu√© se utiliz√≥ (ejemplo: apoyo conceptual, generaci√≥n de ejemplos de c√≥digo, ayuda en redacci√≥n del informe, depuraci√≥n de errores, etc.).  
* **Fragmentos incorporados**: en caso de integrar c√≥digo sugerido por un LLM, especificar cu√°les fragmentos fueron usados y en qu√© archivo/funci√≥n se encuentran.

### Restricciones

El uso de LLMs debe guiarse por las siguientes reglas:

1. **Responsabilidad del grupo**  
   Los integrantes siguen siendo plenamente responsables de **entender, justificar y defender** todo el c√≥digo y documentaci√≥n entregada, aunque hayan usado un LLM como apoyo.

2. **Uso permitido**  
   - Solicitar explicaciones conceptuales.  
   - Generar ejemplos de c√≥digo que luego fueron **adaptados y comprendidos**.  
   - Apoyo en redacci√≥n de documentaci√≥n (ejemplo: `INFORME.md`).  

3. **Uso no permitido**  
   - Entregar c√≥digo generado autom√°ticamente sin comprenderlo ni probarlo.  
   - Modificar el benchmark o los scripts de pruebas para pasar los casos sin implementar realmente el scheduler.  
   - Omitir la declaraci√≥n de uso.  

4. **Evaluaci√≥n**  
   Declarar el uso de LLMs de manera transparente **no afecta negativamente la nota**.  
   Por el contrario, si se muestra c√≥mo se adapt√≥ lo generado para alcanzar una soluci√≥n funcional, esto puede considerarse un aspecto positivo.


